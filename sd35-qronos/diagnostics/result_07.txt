(bacp) C:\Users\Fatim_Sproj\Desktop\Fatim\edge\Project\AI624-Diffusion-Quantization\sd35-qronos>python scripts/diag_07_save_load.py                                                                                                             C:\Users\Fatim_Sproj\anaconda3\envs\bacp\lib\site-packages\torch\cuda\__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.                                                                   import pynvml  # type: ignore[import]                                                                                 2025-12-21 03:57:30.517966: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.                                                                   2025-12-21 03:57:31.172524: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.                                                                   ============================================================                                                            SAVE/LOAD CORRUPTION TEST                                                                                               ============================================================                                                                                                                                                                                    [1/4] FP16 Baseline...                                                                                                  Loading SD 3.5 Medium from stabilityai/stable-diffusion-3.5-medium...                                                   Loading pipeline components...:   0%|                                                            | 0/9 [00:00<?, ?it/s]You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers                                 Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.24it/s] Loading pipeline components...: 100%|████████████████████████████████████████████████████| 9/9 [00:02<00:00,  4.04it/s] Pipeline loaded successfully                                                                                              Transformer: 4.60 GB                                                                                                    Device: cuda:0                                                                                                        100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.12it/s]   Quality: 80.7                                                                                                                                                                                                                                 [2/4] Quantize in memory → generate...                                                                                  Loading SD 3.5 Medium from stabilityai/stable-diffusion-3.5-medium...                                                   Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s] Loading pipeline components...: 100%|████████████████████████████████████████████████████| 9/9 [00:02<00:00,  4.09it/s] Pipeline loaded successfully                                                                                              Transformer: 4.60 GB                                                                                                    Device: cuda:0                                                                                                        100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.72it/s]   Quality: 72.2                                                                                                                                                                                                                                 [3/4] Saving quantized weights...                                                                                         Saved to diagnosis_save_load\temp_quantized_state.pt                                                                    File size: 4.60 GB                                                                                                                                                                                                                            [4/4] Load saved weights → generate...                                                                                  Loading SD 3.5 Medium from stabilityai/stable-diffusion-3.5-medium...                                                   Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.98it/s] Loading pipeline components...: 100%|████████████████████████████████████████████████████| 9/9 [00:02<00:00,  3.76it/s] Pipeline loaded successfully                                                                                              Transformer: 4.60 GB                                                                                                    Device: cuda:0                                                                                                        C:\Users\Fatim_Sproj\Desktop\Fatim\edge\Project\AI624-Diffusion-Quantization\sd35-qronos\scripts\diag_07_save_load.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.                                                                                         saved_state = torch.load(temp_model_path, map_location="cuda")                                                        100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:22<00:00,  4.10s/it]   Quality: 72.2                                                                                                                                                                                                                                 ============================================================                                                            SUMMARY                                                                                                                 ============================================================                                                            FP16 baseline:      80.7                                                                                                Quantized (memory): 72.2                                                                                                Quantized (loaded): 72.2                                                                                                                                                                                                                        ------------------------------------------------------------                                                            WEIGHT VERIFICATION                                                                                                     ------------------------------------------------------------                                                            Loading SD 3.5 Medium from stabilityai/stable-diffusion-3.5-medium...                                                   Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.82it/s] Loading pipeline components...: 100%|████████████████████████████████████████████████████| 9/9 [00:03<00:00,  2.65it/s] Pipeline loaded successfully                                                                                              Transformer: 4.60 GB                                                                                                    Device: cuda:0                                                                                                        Loading SD 3.5 Medium from stabilityai/stable-diffusion-3.5-medium...                                                   Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.00it/s] Loading pipeline components...: 100%|████████████████████████████████████████████████████| 9/9 [00:04<00:00,  2.15it/s] Traceback (most recent call last):                                                                                        File "C:\Users\Fatim_Sproj\Desktop\Fatim\edge\Project\AI624-Diffusion-Quantization\sd35-qronos\scripts\diag_07_save_load.py", line 178, in <module>                                                                                               main()                                                                                                                File "C:\Users\Fatim_Sproj\Desktop\Fatim\edge\Project\AI624-Diffusion-Quantization\sd35-qronos\scripts\diag_07_save_load.py", line 137, in main                                                                                                   pipe2 = load_sd35_pipeline(device="cuda", dtype=torch.float16)                                                        File "C:\Users\Fatim_Sproj\Desktop\Fatim\edge\Project\AI624-Diffusion-Quantization\sd35-qronos\models\sd35_loader.py", line 55, in load_sd35_pipeline                                                                                             pipe = pipe.to(device)                                                                                                File "C:\Users\Fatim_Sproj\anaconda3\envs\bacp\lib\site-packages\diffusers\pipelines\pipeline_utils.py", line 545, in to                                                                                                                          module.to(device, dtype)                                                                                              File "C:\Users\Fatim_Sproj\anaconda3\envs\bacp\lib\site-packages\transformers\modeling_utils.py", line 3850, in to        return super().to(*args, **kwargs)                                                                                    File "C:\Users\Fatim_Sproj\anaconda3\envs\bacp\lib\site-packages\torch\nn\modules\module.py", line 1340, in to            return self._apply(convert)                                                                                           File "C:\Users\Fatim_Sproj\anaconda3\envs\bacp\lib\site-packages\torch\nn\modules\module.py", line 900, in _apply         module._apply(fn)                                                                                                     File "C:\Users\Fatim_Sproj\anaconda3\envs\bacp\lib\site-packages\torch\nn\modules\module.py", line 900, in _apply         module._apply(fn)                                                                                                     File "C:\Users\Fatim_Sproj\anaconda3\envs\bacp\lib\site-packages\torch\nn\modules\module.py", line 900, in _apply         module._apply(fn)                                                                                                     [Previous line repeated 4 more times]                                                                                   File "C:\Users\Fatim_Sproj\anaconda3\envs\bacp\lib\site-packages\torch\nn\modules\module.py", line 927, in _apply         param_applied = fn(param)                                                                                             File "C:\Users\Fatim_Sproj\anaconda3\envs\bacp\lib\site-packages\torch\nn\modules\module.py", line 1326, in convert       return t.to(                                                                                                        torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 23.99 GiB of which 0 bytes is free. Of the allocated memory 53.20 GiB is allocated by PyTorch, and 743.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)                                                                                                         Unhandled exception caught in c10/util/AbortHandler.h                                                                   00007FFD475B839400007FFD47596DC0 torch_python.dll!THPGenerator_initDefaultGenerator [<unknown file> @ <unknown line number>]                                                                                                                    00007FFED00319D700007FFED00319C0 ucrtbase.dll!terminate [<unknown file> @ <unknown line number>]                        00007FF70B4C1C2A00007FF70B4C1110 python.exe!OPENSSL_Applink [<unknown file> @ <unknown line number>]                    00007FFED0425AC300007FFED04258D0 KERNELBASE.dll!UnhandledExceptionFilter [<unknown file> @ <unknown line number>]       00007FFED2CEA5E300007FFED2CE7F50 ntdll.dll!strncpy [<unknown file> @ <unknown line number>]                             00007FFED2CA18A300007FFED2CA1810 ntdll.dll!_C_specific_handler [<unknown file> @ <unknown line number>]                 00007FFED2CE62FF00007FFED2CE6260 ntdll.dll!_chkstk [<unknown file> @ <unknown line number>]                             00007FFED2B9232700007FFED2B91D90 ntdll.dll!RtlLocateExtendedFeature [<unknown file> @ <unknown line number>]            00007FFED2B8A96100007FFED2B8A740 ntdll.dll!RtlRaiseException [<unknown file> @ <unknown line number>]                   00007FFED03D782A00007FFED03D77A0 KERNELBASE.dll!RaiseException [<unknown file> @ <unknown line number>]                 00007FFEBB51526700007FFEBB5151D0 VCRUNTIME140.dll!CxxThrowException [<unknown file> @ <unknown line number>]            00007FFD06B31B3300007FFD06B31000 _pywrap_tensorflow_internal.pyd!PyInit__pywrap_tensorflow_internal [<unknown file> @ <unknown line number>]                                                                                                    00007FFD06B43A7300007FFD06B41F50 _pywrap_tensorflow_internal.pyd!std::list<tensorflow::RunHandler::Impl * __ptr64,std::allocator<tensorflow::RunHandler::Impl * __ptr64> >::~list<tensorflow::RunHandler::Impl * __ptr64,std::allocator<tensorflow::RunHandler::Impl * __ptr64> > [<unknown file> @ <unknown line number>]                                              00007FFD06B4368700007FFD06B41F50 _pywrap_tensorflow_internal.pyd!std::list<tensorflow::RunHandler::Impl * __ptr64,std::allocator<tensorflow::RunHandler::Impl * __ptr64> >::~list<tensorflow::RunHandler::Impl * __ptr64,std::allocator<tensorflow::RunHandler::Impl * __ptr64> > [<unknown file> @ <unknown line number>]                                              00007FFE47D3E5F300007FFE47D3E540 python310.dll!PyCell_Set [<unknown file> @ <unknown line number>]                      00007FFE47D99FEC00007FFE47D99E40 python310.dll!PyTuple_Pack [<unknown file> @ <unknown line number>]                    00007FFE47D62BCD00007FFE47D61DC0 python310.dll!PyFunction_SetAnnotations [<unknown file> @ <unknown line number>]       00007FFE47D62C4600007FFE47D61DC0 python310.dll!PyFunction_SetAnnotations [<unknown file> @ <unknown line number>]       00007FFE47D3E5F300007FFE47D3E540 python310.dll!PyCell_Set [<unknown file> @ <unknown line number>]                      00007FFE47D99FEC00007FFE47D99E40 python310.dll!PyTuple_Pack [<unknown file> @ <unknown line number>]                    00007FFE47D62BCD00007FFE47D61DC0 python310.dll!PyFunction_SetAnnotations [<unknown file> @ <unknown line number>]       00007FFE47CB0FEB <unknown symbol address> python310.dll!<unknown symbol> [<unknown file> @ <unknown line number>]       00007FFE47CB1768 <unknown symbol address> python310.dll!<unknown symbol> [<unknown file> @ <unknown line number>]       00007FFE47E97E0800007FFE47E97090 python310.dll!Py_InitializeMain [<unknown file> @ <unknown line number>]               00007FFE47E987B900007FFE47E98550 python310.dll!Py_FinalizeEx [<unknown file> @ <unknown line number>]                   00007FFE47CBD48800007FFE47CBC930 python310.dll!Py_RunMain [<unknown file> @ <unknown line number>]                      00007FFE47CBD4F600007FFE47CBD4D0 python310.dll!Py_Main [<unknown file> @ <unknown line number>]                         00007FF70B4C149000007FF70B4C1110 python.exe!OPENSSL_Applink [<unknown file> @ <unknown line number>]                    00007FFED1BEE8D700007FFED1BEE8C0 KERNEL32.DLL!BaseThreadInitThunk [<unknown file> @ <unknown line number>]              00007FFED2C0C53C00007FFED2C0C510 ntdll.dll!RtlUserThreadStart [<unknown file> @ <unknown line number>]